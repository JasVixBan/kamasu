\documentclass[10pt]{beamer}
\usepackage{wrapfig}
\usepackage{pgfpages}
\usepackage{listings}
\lstset{language=C++,
basicstyle=\ttfamily,
emph={const,typedef,struct,return,operator,float},       emphstyle=\color{orange},
emph={[2]bp,when,terminal,_value,_child0,_left,_right},  emphstyle={[2]\color{yellow}}
}

\setbeameroption{show notes}
\setbeameroption{show notes on second screen=bottom}

\mode<presentation>
{
  \usetheme{resophonic}
  \setbeamercovered{transparent}
%  \setbeamertemplate{alerted text begin}{hi hi hi}
%  \setbeamertemplate{alerted text end}{end end end}
}

\def\footertext#1{\hbox{\vbox to \logobarheight{
      \vfill\hbox{{\usebeamerfont{logobar}\usebeamercolor[fg]{logobar}#1}}\vfill}}}

% \def\rnote<#1>#2{\note<#1>{\whitesheets #2}}
% \newcommand{\rnote}[2]{ \note#1{#2}}

\addlogo{\footertext{Boostcon 2009}}
\logobartext{Troy D.~Straszheim}

\usepackage{multimedia}

\usepackage[english]{babel}

\usepackage[latin1]{inputenc}

\usepackage{times}
\usepackage[T1]{fontenc}

\def\fleh{\hskip0pt}
\def\py{>\fleh>\fleh>}
\def\launch#1#2{#1<\hskip0pt<\hskip0pt<#2>\hskip0pt>\hskip0pt>}

% \addlogo{blah}
% \def\logobarlogo{hi}

\title[resophonic::kamasu]{\texttt{resophonic::kamasu}}

\subtitle{Computing on the GPU with CUDA and boost::proto}

\author{Troy D. Straszheim}

\institute[Resophonic Systems, Inc.] % (optional, but mostly needed)
{
  Resophonic Systems, Inc.\\
  Washington, DC
}
% - Use the \inst command only if there are several affiliations.
% - Keep it simple, no one is interested in your street address.

\date[BoostCon 2009] % (optional, should be abbreviation of conference name)
{BoostCon, 2009\\
Aspen, CO}
% - Either use conference name or its abbreviation.
% - Not really informative to the audience, more for people (including
%   yourself) who are reading the slides online

\subject{Computer Science}
% This is only inserted into the PDF information catalog. Can be left
% out. 



% If you have a file called "university-logo-filename.xxx", where xxx
% is a graphic format that can be processed by latex or pdflatex,
% resp., then you can add a logo as follows:

% \pgfdeclareimage[height=0.5cm]{university-logo}{university-logo-filename}
% \logo{\pgfuseimage{university-logo}}



% Delete this, if you do not want the table of contents to pop up at
% the beginning of each subsection:
\AtBeginSubsection[]
{
  \begin{frame}<beamer>{Outline}
    \tableofcontents[currentsection,currentsubsection]
  \end{frame}
}

\begin{document}

\begin{frame}
   \note{honored to be here,

    First read modern c++ design in about 2002 or 3, wrote everything
    with policy classes for awhile, still get a thrill out of it

    love this kind of thing as it gives me an opportunity to look in
    to the minds of people that are smarter than I am, and not in
    real-time, and in ascii, so there's little danger that I'll need
    eyebleach

    last year at boostcon, hartmut was encouraging

    i thought great, opportunity to learn proto, look into eric
    niebler's mind

    CUDA was getting buzz

    opportunity to do both, and for the next hour or so I'm going to
    tell you what happened.  these are the proceeds thus far.

    haven't really discussed what I'm doing with anybody yet, so I
    expect you to see lots of things I'm overlooking, looking forward
    to what happens after this talk, lots of time for questions and
    discussion.

    Not a finished product.
   }
   \titlepage
\end{frame}
%   }
% 
\begin{frame}{The Underpants Gnomes' Business Plan}
  \begin{columns}[c]
    \column{0.5\textwidth}
    \begin{enumerate}
    \item Collect Underpants
    \item ???
    \item Profit
    \end{enumerate}
    \column{0.5\textwidth}
    \pgfdeclareimage[height=1in]{x}{underpants_gnomes}
    \pgfuseimage{x}
    \end{columns}
\end{frame}

\begin{frame}{The Kamasu Business Plan}
  \begin{columns}[c]
    \column{0.5\textwidth}
    \begin{enumerate}
    \item Learn boost::proto
    \item Learn CUDA
    \item Combine
    \item ??? \only<2>{\alert<2>{<-  You are here}}
    \item Profit
    \end{enumerate}
    \column{0.5\textwidth}
    \pgfdeclareimage[height=1in]{x}{underpants_gnomes}
    \pgfuseimage{x}
    \end{columns}

  \note{The good news is that the problem-hungry amongst you are about to be well fed

    I haven't written a compiler for the GPU using only templates.

    By combining proto and CUDA I went for cheap laughs, so to speak,
    and I'm sure some of you will find this in bad taste.
}

\end{frame}

\begin{frame}{Outline}
  \tableofcontents
  % You might wish to add the option [pausesections]
\end{frame}

\section{CUDA}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{The GPU vs the CPU}
  \begin{center}
  \pgfdeclareimage[width=4in]{x}{gpuvscpu}
  \pgfuseimage{x}
  \end{center}

  \note{ gpu specialized for compute-intensive, highly parallel
    computation, which is what grahics is all about, so more of it is
    dedicated to doing math.

    it has a lot less sophisticated flow control

    a lot smaller cache

    the green bits are 
    
    presumably that's not to scale
  }
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{The GPU}
  \begin{center}
  \pgfdeclareimage[height=3in]{x}{Device}
  \pgfuseimage{x}
  \end{center}

  \note{ This is Single Instruction Multi Thread, handles hundreds of
    threads running different programs.

    Broken up into Streaming Multiprocessors, seen here, which have
    eight Scalar Processor cores, an instruction unit, shard memory,
    some cache.  This thing creates and manages threads and implements
    \_\_syncthreads() which is for synchronization.

    Constant cache is fast and constant

    Texture cache is fast and constant and has some extra capabilities
    for filtering and whatnot.

    video card GTX 280 in my machine has 30 of these multiprocessors,
    8 cores on each for a total of 240 cores, clock is 1.35GHz

    Each multiprocessor is composed of eight processors, so that a multiprocessor is
    able to process the 32 threads of a warp in four clock cycles.

    There is an organizational scheme that they use involving warps,
    blocks and grids, not very important for the sake of this talk.  }

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Building software to run on the gpu}

nvcc and the like
functions that run on the host only, on the device only,
and callable from the host that run on the device
\end{frame}

\begin{frame}[fragile]{Serially adding a scalar to an array}
  \begin{semiverbatim}void add(float* data, unsigned size, float scalar)
\{
  for(unsigned i=0; i<size; i++) 
    data[i] += scalar;
\}
  \end{semiverbatim}
  \note{looking at how to add a scalar to a vector.

    this is the sequential C version we're all familiar with.
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{Adding a scalar to an array in cuda-parallel}
  \begin{semiverbatim}\alert<2>{__global__} void
add(float *data, float scalar)
\{
  data[\alert<3>{threadIdx.x}] += scalar;
\}
\visible<4>{
int main() \{
  int N = 1024;
  float *arr = make_vector_on_gpu(N);
  
  add<\hskip0pt<\hskip0pt<1, N>\hskip0pt>\hskip0pt>(arr, 3.14159);
\}
}


\end{semiverbatim}

  \note{ This is a 'kernel' or a function that executes on the device,
    but is called by the host.

    the \_\_global\_\_ specifier makes it so.  this function is compiled
    by nvcc into code that runs on the gpu.

    this threadidx is a built in variable that the nvcc compiler puts
    into every kernel function.  it is actually has 3 dimensional
    structure, a 2 dimensional 'grid' of 'blocks', and a thread index
    within the block.

    Here's how we launch it.  First we somehow make an array of N
    elements out on the GPU, we'll get to that, then we use this magic
    anglebracket syntax that NVCC preprocesses into a bunch of
    function calls to an nvidia written library that fetches the
    compiled code for the kernel from wherever its been stored, ships
    it out to the video card, and executes it however many times is
    specified with this grid/block stuff.  From our perspective they
    run simultaneously, though they might be on different
    multiprocessors and whatever.  When threads have to communicate
    with each other or synchronize access to shared memory things get
    more complicated but that's all outside the scope of this talk.

  }
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{CUDA Memory management}
  \begin{semiverbatim}
cudaError_t cudaMalloc(void** devPtr, size_t count );
cudaError_t cudaFree(void* devPtr);

cudaError_t cudaMemcpy(void* dst, const void* src, 
                       size_t count, 
                       enum cudaMemcpyKind kind);

cudaMemcpyHostToHost
cudaMemcpyHostToDevice
cudaMemcpyDeviceToHost
cudaMemcpyDeviceToDevice

cudaError_t cudaMemset(void* devPtr, int value, 
                       size_t count);
  \end{semiverbatim}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{A holder class}
  \begin{semiverbatim}template <typename T>
class holder
\{
    T* devmem;
    std::size_T size_;

  public:

    holder();
    holder(std::size_t n);
    ~holder();
    boost::shared_ptr<holder> clone();
    void resize(std::size_t size);
    T* data() \{ return devmem; \}
    std::size_t size() \{ return size_; \}
\};
\end{semiverbatim}
\note{it isn't an array, it could be the underlying data used by an a ndimensional
  array}
\end{frame}

\begin{frame}[fragile]{holder<T> implementations}
\begin{semiverbatim}template <typename T>
holder<T>::holder(std::size_t s) : size_(s)
\{
   cudaMalloc(reinterpret_cast<void**>(&devmem), 
              size_ * sizeof(T));
\}

template <typename T>
holder<T>::~holder()
\{
  if (devmem)
    cudaFree(devmem);
\}
  \end{semiverbatim}
\end{frame}

\begin{frame}[fragile]{holder<T> implementations}
\begin{semiverbatim}template <typename T>
boost::shared_ptr<holder<T> >
holder<T>::clone()
\{
   boost::shared_ptr<holder> nh(new holder(size_));
   cudaMemcpy(devmem, nh->devmem,
              sizeof(T) * size_,
              cudaMemcpyDeviceToDevice);       
   return nh;
\}
  \end{semiverbatim}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{holder<T> implementations}
\begin{semiverbatim}template <typename T>
void
holder<T>::put(const T* hostmem, std::size_t s)
\{
  if (s != size_)
    resize(s);
  cudaMemcpy(devmem, hostmem, s * sizeof(T),
             cudaMemcpyHostToDevice);
\}

template <typename T>
void
holder<T>::get(T* hostmem)
\{
  cudaMemcpy(hostmem, devmem, size_ * sizeof(T),
             cudaMemcpyDeviceToHost);
\}\end{semiverbatim}

\note{now we just pass these things around at the end of shared
  pointers and we're good when for instance one array is a slice
  of another array}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{numpy arrays}
\begin{semiverbatim}\py a
array([[  1.,   \alert<4>{2.},   3.,   4.,   5.],
\alert<2>{       [  6.,   \alert<5-6>{\alert<4>{7.},   8.,   9.,}  10.],}
       [ 11.,  \alert<5-6>{\alert<4>{12.},  13.,  14.,}  15.],
\alert<3>{       [ 16.,  \alert<4>{17.},  18.,  19.,  20.]}])

\only<2-4>{
\py a[1,:]
\alert<2>{array([  6.,   7.,   8.,   9.,  10.])}

\py a[3,::-1]
\alert<3>{array([ 20.,  19.,  18.,  17.,  16.])}

\py a[:,1]
\alert<4>{array([  2.,   7.,  12.,  17.])}
}\only<5->{
\py a[1:3, 1:4]
array([\alert<5>{[  7.,   8.,   9.],
       [ 12.,  13.,  14.]}])

\py a[2:0:-1, 3:0:-1]
array([\alert<6>{[  9.,   8.,   7.],
       [ 14.,  13.,  12.]}])

}
\end{semiverbatim}
\note{the python bindings for kamasu support exactly this syntax, there is a 
special function called when you use this slicing notation}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{Kamasu arrays}
\begin{semiverbatim}
using resophonic::kamasu::_;

array<float> a(m,n), c(m,n,o,p,q); 

array<float> b = a(index_range(_,_), index_range(2));

b = a(index_range(_,_,-1), index_range(_,_,-1));

float f = b(0,0); // a(9,9)
\end{semiverbatim}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{Kamasu array metadata}
\begin{semiverbatim}

\end{semiverbatim}
\note{arrays can be views of the same data,

semantics is always 'shared' unless you specifically copy something... same as numpy.
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{boost::proto}
\subsection{transforms}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{Life before proto}
\begin{semiverbatim}
array<float> operator+(const array<float>& a, float f);

array<float> a(10), b(10);
a = b + 14;
\end{semiverbatim}
\note{T::T()
T::T()
T::T(float)
T\& T::operator=(T\&\&)
a.value=14

important thing is that the rhs gets eagerly evaluated... the T on the
lhs has only operator=(T\&)

problem is when you try to make that operator+ return a template that
you can evaluate later}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{\alert<4-7>{b} \alert<3>{+} \alert<8-11>{7.0f};}
\begin{semiverbatim}
\alert<2>{expr<
  \alert<3>{tag::plus}, 
  list2<
    \alert<4>{expr<
      \alert<5>{tag::terminal}, 
      \alert<6>{array const&}, 
    >},
    \alert<7>{expr<
      \alert<8>{tag::terminal}, 
      \alert<9>{float const&}, 
    >} 
  >,
>} 
\end{semiverbatim}
\note{ 

  evaluates to this big nested type.

  it has a tag plus, which we'll use later when we want to actually do something
  
  plus has two children, the first is also an expression

  so expressions have tags, like plus, multiplies, comma, or terminal.
  everything is overloaded, that's all done for you.  

  When you see things laid out the way proto lays them out for you it is
  easier to think.  imv.
  
  
% boost::proto::exprns_::expr<boost::proto::tag::plus, boost::proto::argsns_::list2<boost::proto::exprns_::expr<boost::proto::tag::terminal, boost::proto::argsns_::term<bing::matrix&>, 0l>, boost::proto::exprns_::expr<boost::proto::tag::terminal, boost::proto::argsns_::term<int const&>, 0l> >, 2l>

% resophonic::kamasu::Expression<boost::proto::exprns_::expr<boost::proto::tag::plus, boost::proto::argsns_::list2<resophonic::kamasu::array<float>&, resophonic::kamasu::Expression<boost::proto::exprns_::expr<boost::proto::tag::terminal, boost::proto::argsns_::term<int const&>, 0l> > >, 2l> >
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{\visible<1-6>{\alert<6>{b} + 7.0f;}}
\begin{semiverbatim}
\only<1>{boost::proto::}\only<1-2>{exprns_::}expr<
   \only<1>{boost::proto::}tag::plus, 
   \only<1>{boost::proto::}\only<1-2>{argsns_::}list2<
     \only<1>{boost::proto::}\only<1-2>{exprns_::}expr<
       \only<1>{boost::proto::}tag::terminal, 
       \only<1>{boost::proto::}\only<1-2>{argsns_::}\alert<4>{term}\hskip0pt<\alert<6>{array}>, 
       \alert<5>{0}
     >, 
     \only<1>{boost::proto::}\only<1-2>{exprns_::}expr<
       \only<1>{boost::proto::}tag::terminal, 
       \only<1>{boost::proto::}\only<1-2>{argsns_::}\alert<4>{term}\hskip0pt<int const&>, 
       \alert<5>{0}
     > 
   >, 
   \alert<5>{2}
>
\end{semiverbatim}
\note{ 
  actually its more complicated than that

  so the first thing we'll look at is where did this expression come
  from, if this object 'b' is just of type array?  Actually it came
  from someplace irrelevant, but we'll look at how to make this array
  type a proto expression itself.

}
\end{frame}

  % FIXME can't explain this
%  So we have two elementwise additions and a multiplication (which
%  isn't elementwise).  Still haven't thought about things like
%  elementwise multiplication vs matrix multiplication, or how useful
%  they are.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{an array is an expression}
\begin{semiverbatim}
proto::exprns_::\alert<2>{expr}\hskip0pt<
  proto::\alert<3>{tag::terminal}, 
  proto::argsns_::term<\alert<4>{T}>, 
  0
>

\alert<6>{\alert<5>{proto::terminal}\hskip0pt<T>::type}

namespace bp = boost::proto;

struct array_impl \{ /* data goes here */ \};

struct array : proto::terminal<array_impl>::type
\{ ... \};

\end{semiverbatim}
\note{ 

  the overloads that build the expression are defined by proto,
  for this type 'expr' which holds a terminal of some type T

  proto has lots of metafunctions, and this one terminal, luckily,
  will create that expression type for us.

  the array\_impl is also a good place for a compiler firewall since
  we're not doing everything in our headers

  so now this array type participates in all the overloads,
  transforms, domains, grammars and other goodies that proto provides.

}
\end{frame}

  % FIXME can't explain this
%  So we have two elementwise additions and a multiplication (which
%  isn't elementwise).  Still haven't thought about things like
%  elementwise multiplication vs matrix multiplication, or how useful
%  they are.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Hello World}
\begin{semiverbatim}struct array_impl \{ \};

struct array : bp::terminal<array_impl>::type
\{
  template <typename Expr>
  void operator=(const Expr& expr)
  \{
    std::cout << name_of(expr);
  \}
\};

array a, b;
a = b + 7.0f;

boost::proto::exprns_::expr<boost::proto::tag::plus, 
boost::proto::argsns_::list2<array&, boost::proto::e
xprns_::expr<boost::proto::tag::terminal, boost::pro
to::argsns_::term<float const&>, 0l> >, 2l>
\end{semiverbatim}
\note{ 

  the overloads that build the expression are defined by proto,
  for this type 'expr' which holds a terminal of some type T

  proto has lots of metafunctions, and this one terminal, luckily,
  will create that expression type for us.

  the array\_impl is also a good place for a compiler firewall since
  we're not doing everything in our headers

  so now this array type participates in all the overloads,
  transforms, domains, grammars and other goodies that proto provides.

}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{display\_expr}
\begin{semiverbatim}\alert<2>{std::ostream& operator<<(std::ostream& s, array_impl) 
\{
  return s << "array_impl";
\}}

struct array : bp::terminal<array_impl>::type
\{
  template <typename Expr>
  void operator=(const Expr& \alert<4>{expr})
  \{
    std::cout << \alert<3>{bp::display_expr}(\alert<4>{expr});
  \}
\};
\begin{columns}[t]
  \column{0.5\textwidth}\only<-6>{\alert<5>{array a, b;
a = b + 7.0f;


}}\column{0.5\textwidth}\only<6>{\alert<6>{plus(
    terminal(array_impl)
  , terminal(7)
)
}}
\end{columns}
\end{semiverbatim}
\note{ clearly display\_expr has somehow walked the expression tree,
  printing things as it goes along.  Let's do that.
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Overloaded operators}
\begin{semiverbatim}trespasser s, t;   array m, n;
m = \alert<4>{s} \alert<3>{&} \alert<5>{~n} \alert<2>{>>=} \alert<7>{std::cout} \alert<6>{%} \alert<9>{m}\alert<8>{->*}\alert<10>{t};

\alert<2>{shift_right_assign}(
    \alert<3>{bitwise_and}(
        \alert<4>{terminal(trespasser)}
      , \alert<5>{complement(
            terminal(array_impl)
        )}
    )
  , \alert<6>{modulus}(
        \alert<7>{terminal(0x607068)}
      , \alert<8>{mem_ptr}(
            \alert<9>{terminal(array_impl)}
          , \alert<10>{terminal(trespasser)}
        )
    )
)
\end{semiverbatim}
\note{
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Matching expressions}
\begin{semiverbatim}struct grammar
  : bp::or_<bp::terminal<array_impl>,
            bp::terminal<float>,
            bp::plus<grammar, grammar>
            >
\{ \};

template <typename Expr>
void
array::operator=(const Expr& expr)
\{
  std::cout << bp::matches<Expr, grammar>() << "\\n";
\}

m = s & ~m >\hskip0pt>= std::cout % n->*t;   // prints '0'
m = n + 7.0f;                       // prints '1'
\end{semiverbatim}
\note{ 
you can do this with enable\_if, which gives you an error that
looks like roadkill,

or with MPL\_ASSERT, which looks like not so much like roadkill but
like something that is just injured, with the stars around its head
there.  but at least should give the user the idea that the errror is
on purpose, library is trying to tell him something, not that he
hasn't found a bug }
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]{Detecting invalid expressions}
\begin{semiverbatim}template <typename Expr>
\only<1,4->{void}\only<2-3>{\alert<2>{typename enable_if<bp::matches<Expr, grammar> >::type}}
array::operator=(const Expr& expr)
\{
  // to come: do something with expr
  \only<4->{\alert<4>{BOOST_MPL_ASSERT((bp::matches<Expr, grammar>));}}
\}

m = s & ~m >\hskip0pt>= std::cout % n->*t;
\only<1-2,4>{






}\only<3>{\alert<3>{error: no match for 'operator=' in 'm = boost::prot
o::exprns_::operator>>= [with Left = boost::proto::
exprns_::expr<boost::proto::tag::bitwise_and, boost
::proto::argsns_::list2<boost::proto::exprns_::expr
<boost::proto::tag::terminal, boost::proto::argsns_
::term<trespasser&>, 0l>, const boost::proto::exprn
s_::expr<boost::proto::tag::complement, boost::prot
o::argsns_::list1<boost::proto::exprns_::expr<bo...}}\only<5-6>{error: no matching function for call to 'assertion_
failed(mpl_::failed\alert<6>{************ }boost::proto::resul
t_of::matches<boost::proto::exprns_::expr<boost::pr
oto::tag::shift_right_assign, boost::proto::argsns_
::list2<const boost::proto::exprns_::expr<boost::pr
oto::tag::bitwise_and, boost::proto::argsns_::list2
<boost::proto::exprns_::expr<boost::proto::tag::ter
mina  ....  proto::a>, 2l>, grammar>::\alert<6>{************})'}
\end{semiverbatim}
\note{ 
you can do this with enable\_if, which gives you an error that
looks like roadkill,

or with MPL\_ASSERT, which looks like roadkill with stars around its
head.  not so much like roadkill but like something that is just
injured, with the stars around its head there.  but at least should
give the user the idea that the errror is on purpose, library is
trying to tell him something, not that he hasn't found a bug }
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{Transforms}
\begin{semiverbatim}
struct array_impl \{ float value; \};
struct array : bp::terminal<array_impl>::type
\{ /* ... */ \};

array \alert<2>{a};

\alert<3>{array_impl& aimpl =}
\alert<4>{   a.child0;}          // via base class
\alert<5>{   bp::value(a);}      // free function
   \alert<8>{\alert<7>{\alert<6>{bp::_value}()}(a);}   // instance of _value
   \alert<9>{bp::_child0()(a);}  // instance of _child0
   \alert<10>{bp::child_c<0>(a);}
   \alert<11>{bp::child<mpl::long_<0> >(a);}
   \alert<12>{bp::_left()(a);}    // instance of _left
   \alert<13>{bp::left(a);}       // left function
\end{semiverbatim}
\note{ \_value the type is different than value the free function for a
  very important reason and spectacularly nifty trick, we'll see in a
  minute.

  so what is the return type of the function bp::value?  it is the
  result of running the transform \_value on the object.  How is that
  determined?  By types nested inside this \_value transform type.
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{More transforms}
\begin{semiverbatim}
struct array_impl \{ float value; \};
struct array : bp::terminal<array_impl>::type \{ ... \};
array t;

\alert<4>{\only<4-5>{bp::display_expr(}\alert<2>{t + 2}\only<4-5>{)}}
\begin{columns}[t]
  \column{0.5\textwidth}\alert<3>{expr<
  tag::plus 
, list2<
    array&
  , expr<
      tag::terminal 
    , term<int const&> 
    , 0
    > 
  >
, 2
>}
\column{0.5\textwidth}\alert<5>{plus(
    terminal(array_impl)
  , terminal(2)
)}
\end{columns}



\end{semiverbatim}
\note{ }
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{More transforms}
\begin{semiverbatim}
struct array_impl \{ float value; \};
struct array : bp::terminal<array_impl>::type \{ ... \};
array t;

\only<1>{bp::display_expr(t + 2)
}\only<2>{bp::display_expr(bp::child1(t + 2))
}\only<3>{std::cout << bp::value(bp::child1(t + 2))}


\only<1>{plus(
    terminal(array_impl)
  , terminal(2)
)}\only<2>{terminal(2)


}\only<3>{2



}


\end{semiverbatim}
\note{ }
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{Avoiding temporaries 1: emulating rvalues}
\begin{semiverbatim}
struct \alert<2>{CopyLValue} : bp::callable
\{
  typedef array_impl<float> result_type;

  result_type
  operator()(const array_impl<float>& a)
  \{
    return a.clone();
  \}
\};


struct RkArrayTerminal 
  : bp::when<bp::terminal<rk::array_impl<float> >, 
             CopyLValue(bp::_value)>
\{ \};


\end{semiverbatim}
\note{

}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 
% \begin{frame}[fragile]{Avoiding temporaries 2: use the LHS}
% \begin{semiverbatim}
% 
% rk::array<float> a(10, 10);
% 
% a = sin(a);
% 
% \end{semiverbatim}
% \note{
%   in practice the LHS 
% }
% \end{frame}
% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]{Avoiding temporaries 2: reuse the LHS}
\begin{semiverbatim}
struct CopyLValue : bp::callable
\{
  typedef array_impl<float> result_type;

  result_type
  operator()(const array_impl<float>& a, data_t& data)
  \{
    if (data.tmp == &a) \{ data.tmp = 0; return a; \} 
    else                \{ return a.clone();       \}
  \}
\};

struct RkArrayTerminal 
  : bp::when<bp::terminal<rk::array_impl<float> >, 
             CopyLValue(bp::_value, bp::_data)>
\{ \};


\end{semiverbatim}
\note{
  in practice the LHS 
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Related efforts}

\begin{frame}[fragile]{PyCuda (Andreas Kl\"ockner)}
  \begin{semiverbatim}import pycuda.autoinit, pycuda.driver as drv, numpy

mod = drv.SourceModule("""
__global__ void multiply_them(float *dest, float *a, float *b)
\{
  const int i = threadIdx.x;
  dest[i] = a[i] * b[i];
\}
""")

multiply_them = mod.get_function("multiply_them")
a = numpy.random.randn(400).astype(numpy.float32)
b = numpy.random.randn(400).astype(numpy.float32)
dest = numpy.zeros_like(a)
multiply_them(
    drv.Out(dest), drv.In(a), drv.In(b),
    block=(400,1,1))
print dest-a*b
  \end{semiverbatim}


  \note{the pycuda approach uses cuda's jit engine.  

    you can use any
    of various templating engines to 'metaprogram'}

\end{frame}

\section{resophonic::kamasu}
\subsection{benchmarks}

\end{document}


